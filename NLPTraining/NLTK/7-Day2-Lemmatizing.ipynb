{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\r\n",
    "What is Lemmatization ?\r\n",
    "\r\n",
    "Lemmatization is the process of grouping together the different inflected forms of a word so they can be analysed as a single item.\r\n",
    "Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meaning to one word.\r\n",
    "\r\n",
    "Text preprocessing includes both Stemming as well as Lemmatization. Many times people find these two terms confusing. \r\n",
    "Some treat these two as same. Actually, lemmatization is preferred over Stemming because lemmatization does morphological\r\n",
    "analysis of the words.\r\n",
    "\r\n",
    "Applications of lemmatization are:\r\n",
    "\r\n",
    "-Used in comprehensive retrieval systems like search engines.\r\n",
    "-Used in compact indexing\r\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_words = [\"word\", \"wordy\", \"wording\", \"cacti\", \"rocks\", \"catty\", \"demonic\", \"geese\", \"ravishing\", \"better\", \"best\", \"run\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      "wordy\n",
      "wording\n",
      "cacti\n",
      "rocks\n",
      "catty\n",
      "demonic\n",
      "geese\n",
      "ravishing\n",
      "good\n",
      "best\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "for w in example_words:\r\n",
    "    print(lemmatizer.lemmatize(w, pos=\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      "wordy\n",
      "word\n",
      "cacti\n",
      "rock\n",
      "catty\n",
      "demonic\n",
      "geese\n",
      "ravish\n",
      "better\n",
      "best\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "for w in example_words:\r\n",
    "    print(lemmatizer.lemmatize(w, pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      "wordy\n",
      "wording\n",
      "cactus\n",
      "rock\n",
      "catty\n",
      "demonic\n",
      "goose\n",
      "ravishing\n",
      "better\n",
      "best\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "for w in example_words:\r\n",
    "    print(lemmatizer.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional\r\n",
    "# i) WordNetLemmatizer() without POS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She ---> She\n",
      "jumped ---> jumped\n",
      "into ---> into\n",
      "the ---> the\n",
      "river ---> river\n",
      "and ---> and\n",
      "breathed ---> breathed\n",
      "heavily ---> heavily\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "\r\n",
    "text = \"She jumped into the river and breathed heavily\"\r\n",
    "wordnet = WordNetLemmatizer()\r\n",
    "tokenizer = word_tokenize(text)\r\n",
    "\r\n",
    "for token in tokenizer:\r\n",
    "    print(token,\"--->\",wordnet.lemmatize(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ---> I\n",
      "am ---> am\n",
      "running ---> running\n",
      "and ---> and\n",
      "I ---> I\n",
      "usually ---> usually\n",
      "use ---> use\n",
      "to ---> to\n",
      "runs ---> run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "\r\n",
    "text = \"I am running and I usually use to runs\"\r\n",
    "\r\n",
    "wordnet = WordNetLemmatizer()\r\n",
    "tokenizer = word_tokenize(text)\r\n",
    "\r\n",
    "for token in tokenizer:\r\n",
    "    print(token,\"--->\",wordnet.lemmatize(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ii) WordNetLemmatizer() with POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She ---> She\n",
      "jumped ---> jump\n",
      "into ---> into\n",
      "the ---> the\n",
      "river ---> river\n",
      "and ---> and\n",
      "breathed ---> breathe\n",
      "heavily ---> heavily\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\r\n",
    "from nltk import word_tokenize,pos_tag\r\n",
    "\r\n",
    "text = \"She jumped into the river and breathed heavily\"\r\n",
    "wordnet = WordNetLemmatizer()\r\n",
    "\r\n",
    "for token,tag in pos_tag(word_tokenize(text)):\r\n",
    "    pos=tag[0].lower()\r\n",
    "        \r\n",
    "    if pos not in ['a', 'r', 'n', 'v']:\r\n",
    "        pos='n'\r\n",
    "    \r\n",
    "    print(token,\"--->\",wordnet.lemmatize(token,pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ---> I\n",
      "am ---> be\n",
      "running ---> run\n",
      "and ---> and\n",
      "I ---> I\n",
      "usually ---> usually\n",
      "use ---> use\n",
      "to ---> to\n",
      "runs ---> run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\r\n",
    "from nltk import word_tokenize,pos_tag\r\n",
    "\r\n",
    "text = \"I am running and I usually use to runs\"\r\n",
    "wordnet = WordNetLemmatizer()\r\n",
    "\r\n",
    "for token,tag in pos_tag(word_tokenize(text)):\r\n",
    "    pos=tag[0].lower()\r\n",
    "        \r\n",
    "    if pos not in ['a', 'r', 'n', 'v']:\r\n",
    "        pos='n'\r\n",
    "    \r\n",
    "    print(token,\"--->\",wordnet.lemmatize(token,pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStemming vs Lemmatization\\nAlthough both look quite similar there are key differences between Stemming vs Lemmatization –\\n\\n-The output of lemmatization is an actual word like Changing -> Change\\nbut stemming may not produce an actual English word like Changing -> Chang.\\n\\n-The stemming process just follows the step-by-step implementation of algorithms like SnowBall, Porter, etc.\\nto derive the stem. Whereas lemmatization makes use of a lookup database like WordNet to derive lemma. \\nFor example, the lemmatization of “better” is “well” and this another word is derived as lemma as it looks up in the dictionary.\\nBut the stemming result will come as “better” only without a lookup.\\nHowever, this lookup can at times slow down the lemmatization process.\\n\\n-Stemming does not take the context of the word into account, for example, “meeting” can be a verb or noun based on the context. \\nBut lemmatization does consider the context of the word before generating its lemma.\\n\\nStemming vs Lemmatization Example\\nIn the example code below we first tokenize the text and then with the help of for loop stemmed the token with Snowball Stemmer\\nand Porter Stemmer. At the same time, we also Lemmatize the text and convert it into a lemma with the help of Wordnet Lemmatizer.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\r\n",
    "Stemming vs Lemmatization\r\n",
    "Although both look quite similar there are key differences between Stemming vs Lemmatization –\r\n",
    "\r\n",
    "-The output of lemmatization is an actual word like Changing -> Change\r\n",
    "but stemming may not produce an actual English word like Changing -> Chang.\r\n",
    "\r\n",
    "-The stemming process just follows the step-by-step implementation of algorithms like SnowBall, Porter, etc.\r\n",
    "to derive the stem. Whereas lemmatization makes use of a lookup database like WordNet to derive lemma. \r\n",
    "For example, the lemmatization of “better” is “well” and this another word is derived as lemma as it looks up in the dictionary.\r\n",
    "But the stemming result will come as “better” only without a lookup.\r\n",
    "However, this lookup can at times slow down the lemmatization process.\r\n",
    "\r\n",
    "-Stemming does not take the context of the word into account, for example, “meeting” can be a verb or noun based on the context. \r\n",
    "But lemmatization does consider the context of the word before generating its lemma.\r\n",
    "\r\n",
    "Stemming vs Lemmatization Example\r\n",
    "In the example code below we first tokenize the text and then with the help of for loop stemmed the token with Snowball Stemmer\r\n",
    "and Porter Stemmer. At the same time, we also Lemmatize the text and convert it into a lemma with the help of Wordnet Lemmatizer.\r\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word        Snowball Stemmer    Porter Stemmer      Wordnet Lemmatizer  \n",
      "better      better              better              well                \n",
      "Caring      care                care                Caring              \n",
      "are         are                 are                 be                  \n",
      "am          am                  am                  be                  \n",
      "worse       wors                wors                worse               \n",
      "struggling  struggl             struggl             struggle            \n",
      "meeting     meet                meet                meeting             \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer, PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "snowball = SnowballStemmer(language='english')\n",
    "porter = PorterStemmer()\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "text = [\"better\", \"Caring\", \"are\", \"am\", \"worse\", \"struggling\", 'meeting']\n",
    "\n",
    "print(\"{:<12}{:<20}{:<20}{:<20}\".format(\"Word\", \"Snowball Stemmer\", \"Porter Stemmer\", \"Wordnet Lemmatizer\"))\n",
    "\n",
    "for token, tag in pos_tag(text):\n",
    "    pos = tag[0].lower()\n",
    "    if pos not in ['a', 'r', 'n', 'v']:\n",
    "        pos = 'n'\n",
    "    print(\"{:<12}{:<20}{:<20}{:<20}\".format(\n",
    "        token,\n",
    "        snowball.stem(token),\n",
    "        porter.stem(token),\n",
    "        wordnet.lemmatize(token, pos)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "135e78ef6267b613ce7b86630936d470174b66187aad9f784a45e5cc3235687c"
  },
  "kernelspec": {
   "display_name": "nlpvenv",
   "language": "python",
   "name": "nlpvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
